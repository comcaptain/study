# Course Links

- [Cloud Practitioner - Digital and Classroom Training | AWS (amazon.com)](https://aws.amazon.com/training/learn-about/cloud-practitioner/)



# Course 1: Job Roles in the Cloud

## Shared Responsibility Model

AWS is responsible for security of  the cloud and customer is responsible for security in the cloud. 

- The customer assumes responsibility and management of the guest operating system, including updates and security patches.
- The customer also assumes responsibility for other associated application software and the configuration of the AWS provided security group firewall.

# Course 2: AWS Cloud Practitioner Essentials



## Module 1 Introduction to Amazon Web Services

### Benefit of AWS:

1. only pay for what you need

   - You don't need to pay for extra hardware if you do not have that much traffic like in the midnight

   - You can tripple your hardware resource on-demand when high traffic comes

2. AWS helps you do stuff that most of the IT department needs to do but does not make your business better than the competitors

   - e.g. Installing a mysql database and upgrade it

### Interaction with AWS

Every action that you make in AWS is an API call that is authenticated and authorized. In AWS, you can make API calls to services and resources through the AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS SDKs.

## Module 2 Compute in the Cloud

### EC2 instance types

- General purpose instance
- Compute optimized instances
- Memory optimized instance
  - e.g. high-performance database
- Accelerated computing instances
  - Use hardware accelerators, or coprocessors, to perform some functions more efficiently than is possible in software running on CPUs
  - e.g. Graphics processing
- Storage optimized instances
  - Like data warehousing applications

### EC2 Pricing 

- On-Demand
  - Ad-hoc, short-term contract, more expensive than reserved instances


- Reserved Instances
  - Long-term contract, cheaper than on-demand
  - Two categries:
    - Standard Reserved Instances
    - Convertible Reserved Instances: more flexible, you can change instance type, availability zone... But it's more expensive

- Savings Plans
  - High-customized plan
- Spot Instances
  - Cheapest one. Your program would only be run when there is free computing resource
  - And your program can be interrupted if computing resource short 
- Dedicated Hosts
  - Dedicated physical machines, most expensive


### Scaling Amazon EC2

Auto-scaling group: minimum capacity, desired capacity, max capacity

### Elastic Load Balancing

Short name is ELB. Is a service that AWS enables. Can work together with auto-scaling group

### Amazon Simple Notification Service (Amazon SNS)

**Amazon Simple Notification Service (Amazon SNS)** is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. This is similar to the coffee shop; the cashier provides coffee orders to the barista who makes the drinks.

Amazon SNS (Simple Notification Service) is a fully managed messaging service provided by AWS for both application-to-application (A2A) and application-to-person (A2P) communication. It's designed to enable scalable and flexible messaging. Key features include:

- **Pub/Sub Messaging**: Facilitates a publisher/subscriber model, allowing messages to be sent to multiple subscribers.
- **Multiple Protocol Support**: Messages can be sent via various protocols including HTTP, HTTPS, email, SMS, and to AWS Lambda functions or SQS queues.
- **Topic-Based Distribution**: Organizes messages into topics for high-throughput, push-based, many-to-many messaging.
- **Scalability**: Automatically scales to handle large numbers of messages and subscribers.
- **Durability**: Highly reliable infrastructure ensures message delivery.
- **Flexible Message Delivery**: Supports direct sending of messages to users via SMS, email, or AWS services like Lambda for processing.
- **Integration**: Seamlessly integrates with other AWS services for comprehensive cloud-based applications.
- **Security**: Offers encryption and access control capabilities to secure messages.

Common use cases for SNS include notifications, workflow systems, time-sensitive information updates, and mobile communication. It's a robust solution for managing communication and messaging in the cloud, ensuring scalable and efficient delivery of messages.

### **Amazon Simple Queue Service (Amazon SQS)**

Amazon SQS (Simple Queue Service) is a fully managed message queuing service offered by AWS. It enables the decoupling and scaling of microservices, distributed systems, and serverless applications. Key features include:

- **Message Queuing**: Allows storage of messages in a queue to be processed asynchronously.
- **Scalability**: Automatically scales to handle any volume of messages without any upfront provisioning.
- **Durability and Availability**: Offers high message durability and availability across multiple Availability Zones.
- **Two Types of Queues**:
  - **Standard Queues**: Offer maximum throughput, best-effort ordering, and at-least-once delivery.
    - This is fast
  - **FIFO Queues**: Guarantee the order in which messages are sent and received, and ensure exactly-once processing.
- **Integration**: Seamlessly integrates with other AWS services for building scalable and flexible applications.
- **Security**: Supports encryption at rest and in transit, and allows control access using AWS IAM.
- **Use Cases**: Widely used for building robust applications such as workflow systems, task queues, application integration, and data processing pipelines.

### Serverless computing

It's like application container. You do not have to manage or care about the servers that your application run on

#### AWS Lambda

[**AWS Lambda**(opens in a new tab)](https://aws.amazon.com/lambda) is a service that lets you run code without needing to provision or manage servers. 

While using AWS Lambda, you pay only for the compute time that you consume. Charges apply only when your code is running. You can also run code for virtually any type of application or backend service, all with zero administration. 

1. You upload your code to Lambda. 
2. You set your code to trigger from an event source, such as AWS services, mobile applications, or HTTP endpoints.
3. Lambda runs your code only when triggered.
4. You pay only for the compute time that you use. In the previous example of resizing images, you would pay only for the compute time that you use when uploading new images. Uploading the images triggers Lambda to run code for the image resizing function.

#### AWS Fargate

[**AWS Fargate**(opens in a new tab)](https://aws.amazon.com/fargate/) is a serverless compute engine for containers. It works with both Amazon ECS and Amazon EKS. 

When using AWS Fargate, you do not need to provision or manage servers. AWS Fargate manages your server infrastructure for you. You can focus more on innovating and developing your applications, and you pay only for the resources that are required to run your containers.

### Amazon Elastic Container Service (Amazon ECS)

[**Amazon Elastic Container Service (Amazon ECS)**(opens in a new tab)](https://aws.amazon.com/ecs/) is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. This supports docker

### Amazon Elastic Kubernetes Service (Amazon EKS)

[**Amazon Elastic Kubernetes Service (Amazon EKS)**(opens in a new tab)](https://aws.amazon.com/eks/) is a fully managed service that you can use to run Kubernetes on AWS. 

[Kubernetes(opens in a new tab)](https://kubernetes.io/) is open-source software that enables you to deploy and manage containerized applications at scale.

## Module 3 Global Infrastructure and Reliability

### Region Selection

When you decide which AWS Region to host your applications and workloads, consider four main aspects: latency, price, service availability, and compliance.

### Availability Zone

An **Availability Zone** is a single data center or a group of data centers within a Region. Availability Zones are located tens of miles apart from each other. This is close enough to have low latency (the time between when content requested and received) between Availability Zones. However, if a disaster occurs in one part of the Region, they are distant enough to reduce the chance that multiple Availability Zones are affected.

One region would contain one or more availability zones

Regional services are by definition already highly available at no additional cost of effort on your part. 

#### Name

Availability Zones also have code names. Because they are located inside Regions, they can be addressed by appending a letter to the end of the Region code name. Here are examples of Availability Zone codes:

- **us-east-1a** is an Availability Zone in us-east-1 (N. Virginia Region).
- **sa-east-1b** is an Availability Zone in sa-east-1 (SÃ£o Paulo Region).

Therefore, if you see that a resource exists in us-east-1c, you can infer that the resource is located in Availability Zone c of the us-east-1 Region.

### Wavelength Zone

One AWS Region can contain multiple Wavelength Zones. Each Wavelength Zone is an extension of an AWS Region and is located within the network of a telecommunications provider to deliver ultra-low latency applications to mobile and connected devices. This setup allows developers to deploy applications closer to end-users while still being connected to the broader range of services and infrastructure provided by the AWS Region.

### Scope of AWS services

For Region-scoped services, AWS automatically performs actions to increase data durability and availability.

On the other hand, some services ask you to specify an Availability Zone. With these services, you are often responsible for increasing the data durability and high availability of these resources.

### Edge locations

An **edge location** is a site that Amazon CloudFront (amazon's CDN) uses to store cached copies of your content closer to your customers for faster delivery.

### AWS global accelerator

AWS Global Accelerator improves the performance of your applications by routing user traffic through the AWS global network infrastructure. It works by:

1. **Anycast IP Addresses:** Provides two static anycast IP addresses that serve as a fixed entry point to your applications in any AWS Region. These IP addresses are used to route user traffic to the nearest AWS edge location.
2. **Edge Network:** Utilizes the AWS global network to route user traffic from edge locations to your application endpoints in AWS Regions. This network is optimized for speed and reliability.
3. **Endpoint Groups:** Traffic is directed to endpoint groups, each associated with a specific AWS Region. Within each endpoint group, you can configure one or more application endpoints, such as Network Load Balancers, Application Load Balancers, EC2 instances, or Elastic IPs.
4. **Traffic Dials:** Allows you to control the amount of traffic directed to each endpoint group, enabling performance testing or phased rollouts.
5. **Health Checks:** Automatically performs health checks on your application endpoints and directs traffic away from unhealthy endpoints, improving the overall availability of your application.
6. **Performance Optimization:** By routing traffic over the AWS backbone network, it reduces internet latency and jitter, providing a more consistent and optimized user experience.

Global Accelerator is especially beneficial for applications with a global user base, where managing latency and improving network performance are crucial.

#### Difference & similarity with load balancer

AWS Global Accelerator can be thought of as a global-level load balancer, but with some distinct characteristics and functionalities. Hereâs how it aligns and differs from a traditional load balancer:

**Similarities with Load Balancers:**

1. **Traffic Distribution:** Both distribute user traffic across multiple destinations or endpoints.
2. **High Availability and Redundancy:** They increase application availability and redundancy by routing traffic to healthy endpoints.
3. **Performance Improvement:** Aim to improve the performance of applications by efficiently managing network traffic.

**Unique Aspects of AWS Global Accelerator:**

1. **Global Scope:** Operates at a global level using the AWS global network, which reduces latency and improves the performance of your application by routing user traffic through the nearest AWS edge location.
2. **Anycast IP Addresses:** Provides two static anycast IP addresses that route user traffic to the nearest edge location, and from there to your application endpoints in AWS Regions.
3. **Network Optimization:** Uses the AWS global network backbone, offering users a consistent, low-latency experience regardless of their geographical location.
4. **Endpoint Groups:** Allows traffic to be directed to different endpoint groups (each located in different AWS Regions) based on performance, geography, or other criteria.

While traditional load balancers (like AWS ELB) operate within a region or an availability zone, AWS Global Accelerator extends its functionality globally, optimizing the route for user traffic across the entire AWS network.

## Module 4 Networking

### CIDR



![The number after the forward slash denotes how many bits in an IP address are fixed.](./assets/Pjs0q13feA_j6wDK_spqIyeTVAORW0ECH.png)



It begins with a starting IP address and is separated by a forward slash (the */* character) followed by a number. The number at the end specifies how many of the bits of the IP address are fixed. In this example, the first 24 bits of the IP address are fixed. The rest (the last 8 bits) are flexible.

### Amazon Virtual Private Cloud (Amazon VPC)

A networking service that you can use to establish boundaries around your AWS resources is [**Amazon Virtual Private Cloud (Amazon VPC)**(opens in a new tab)](https://aws.amazon.com/vpc/).

Amazon VPC enables you to provision an isolated section of the AWS Cloud. In this isolated section, you can launch resources in a virtual network that you define. Within a virtual private cloud (VPC), you can organize your resources into subnets. A **subnet** is a section of a VPC that can contain resources such as Amazon EC2 instances.

#### Create a VPC

A virtual private cloud (VPC) is an isolated network that you create in the AWS Cloud, similar to a traditional network in a data center. When you create an Amazon VPC, you must choose three main factors:

- Name of the VPC
- Region where the VPC will live â A VPC spans all the Availability Zones within the selected Region.
- IP range for the VPC in CIDR notation â This determines the size of your network. Each VPC can have up to five CIDRs: one primary and four secondaries for IPv4. Each of these ranges can be between /28 (in CIDR notation) and /16 in size.

Using this information, AWS will provision a network and IP addresses for that network.

![When a VPC is created, you specify a CIDR block for the VPC. The VPC will span all the AZs within the selected Region.](./assets/t39keaPeCKlHVRKP_KKtsB2WCJm3nf8cP.png)

### Internet gateway

To allow public traffic from the internet to access your VPC, you attach an **internet gateway** to the VPC. Think of the gateway as similar to a modem.



![img](./assets/DniMlox3h6MNwAKp_NEblbQjD0vn0-pPU.png)

Internet gateway icon attached to a VPC that holds three EC2 instances. An arrow connects the client to the gateway over the internet indicating that the client's request has gained access to the VPC.

### Virtual private gateway

To access private resources in a VPC from your on-premises data center, you can use a **virtual private gateway**. 

![A corporate data center routes network traffic over a VPN connection to a virtual private gateway, which is attached to a VPC](./assets/sOWN4dAWZ2h3q9Od_s8U3lQzEONXm1FMX.png)

### **AWS Direct Connect**

[**AWS Direct Connect**(opens in a new tab)](https://aws.amazon.com/directconnect/) is a service that lets you to establish a **dedicated** private connection between your data center and a VPC.  It would be a dedicated private pysical cable, not shared with anyone else

![img](./assets/tQJ2xNzQ_TXe2TUR_YdzRvczPABE_j-yV.png)

### NAT Gateway

A NAT (Network Address Translation) Gateway in AWS is a service that allows instances in a private subnet to connect to the internet or other AWS services while preventing the internet from initiating a connection with those instances. Key characteristics of a NAT Gateway in AWS include:

1. **Internet Access for Private Subnets:** Enables instances in a private subnet to send outbound traffic to the internet (e.g., for software updates) and receive the response traffic.
2. **Security:** Since it doesn't allow inbound traffic initiated from the internet, it enhances the security of resources in the private subnet.
3. **Managed Service:** AWS manages the NAT Gateway, providing high availability and automatic scaling.
4. **IP Addressing:** It translates the private IP addresses of instances in the private subnet to a public IP address and vice versa for the inbound response.
5. **Billing:** Charged based on the amount of data it processes and the optional provision of an Elastic IP address.
6. **Scalability and Availability:** Automatically scales up to handle large volumes of traffic with high availability but is not shared across Availability Zones. You need to create a NAT Gateway in each Availability Zone where you have private subnets.

NAT Gateways are commonly used in a VPC setup where secure and controlled internet access is necessary for instances without exposing them directly to the internet.

### VPC Peering

VPC Peering is a networking connection between two Virtual Private Clouds (VPCs) that enables you to route traffic between them using private IP addresses. Instances in either VPC can communicate as if they were in the same network. Key characteristics include:

- **Isolation and Security**: Maintains the isolated nature of VPCs while allowing inter-VPC communication.
- **Network Overlap**: VPCs cannot have overlapping IP ranges.
- **Cross-Account Peering**: Supports peering between VPCs in different AWS accounts.
- **Transitive Peering**: Not natively supported; traffic between VPCs must be directly peered.
- **Region Support**: Can be established between VPCs in different regions (Inter-Region VPC Peering).

Common use cases involve resource sharing, data access consolidation, and simplified network architecture in a secure and efficient manner.

### VPC Endpoint

A VPC endpoint enables private connections between your Virtual Private Cloud (VPC) and AWS services without requiring the traffic to traverse the public internet. Key aspects include:

- **Types**:
  - **Gateway Endpoints**: For S3 and DynamoDB. Routes traffic through a gateway attached to your VPC.
  - **Interface Endpoints**: For other AWS services. Uses an Elastic Network Interface (ENI) with a private IP.
- **Security and Privacy**: Enhances security by keeping traffic within the AWS network.
- **Access Control**: Security groups and endpoint policies can be used to control access.
- **Connectivity**: Allows VPC resources to access AWS services without public IPs or NAT devices.
- **Cost-Effective**: Reduces data transfer costs for traffic to AWS services.

Commonly used for secure and private communication with services like S3, EC2, Lambda, and others within AWS.

### AWS PrivateLink

AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises applications, securely on the AWS network. Key features include:

- **Service Exposure**: Allows service owners to offer services (accessible via an endpoint) to other AWS accounts.
- **Privacy & Security**: Traffic doesn't traverse the public internet, reducing exposure to threats.
- **Endpoint Services**: Utilizes Network Load Balancers to expose services to other VPCs.
- **Ease of Use**: Simplifies network architecture by connecting services directly.
- **Integration**: Works with various AWS services and can be used to access services hosted by other AWS accounts.

Commonly used for secure, private connections to third-party services, SaaS applications, and AWS Marketplace services.

### Subnets

A subnet is a section of a VPC in which you can group resources based on security or operational needs. One subnet can only exist in one specific availability zone. Subnets can be public or private. 



<img src="./assets/k7zJ9N7vB7HAQx_j_pi4TpfvEYaalWuIu.png" alt="VPC with three Amazon EC2 instances in a public subnet and three databases in a private subnet." style="zoom:25%;" />

**Public subnets** contain resources that need to be accessible by the public, such as an online storeâs website.

**Private subnets** contain resources that should be accessible only through your private network, such as a database that contains customersâ personal information and order histories. 

In a VPC, subnets can communicate with each other. For example, you might have an application that involves Amazon EC2 instances in a public subnet communicating with databases that are located in a private subnet.

#### Create a subnet

After you create your VPC, you must create subnets inside the network. Think of subnets as smaller networks inside your base network, or virtual local area networks (VLANs) in a traditional, on-premises network. In an on-premises network, the typical use case for subnets is to isolate or optimize network traffic. In AWS, subnets are used to provide high availability and connectivity options for your resources. Use a public subnet for resources that must be connected to the internet and a private subnet for resources that won't be connected to the internet.



![You can launch AWS resources, such as EC2 instances, into a specific subnet within your VPC.](./assets/T9GKeeYk2PJpXmoA_jUajvREe6Ry6idlJ.png)



When you create a subnet, you must specify the following:

- **VPC** that you want your subnet to live inâin this case: VPC (10.0.0.0/16)
- **Availability Zone** that you want your subnet to live inâin this case: Availability Zone 1
- **IPv4 CIDR block for your subnet**, which must be a subset of the VPC CIDR blockâin this case: 10.0.0.0/24

When you launch an EC2 instance, you launch it inside a subnet, which will be located inside the Availability Zone that you choose.

### Reserved IPs 

For AWS to configure your VPC appropriately, AWS reserves five IP addresses in each subnet. These IP addresses are used for routing, Domain Name System (DNS), and network management.

![AWS reserves five IP addresses in each subnet that cannot be assigned to a resource.](./assets/yVvxJRoMUxkJyMC6_Octk-lV6RnrruL3M.png)

### Amazon VPC Routing

#### Main route table

When you create a VPC, AWS creates a route table called the main route table. A route table contains a set of rules, called routes, that are used to determine where network traffic is directed. AWS assumes that when you create a new VPC with subnets, you want traffic to flow between them. Therefore, the default configuration of the main route table is to allow traffic between all subnets in the local network. The following rules apply to the main route table:

- You cannot delete the main route table.
- You cannot set a gateway route table as the main route table.
- You can replace the main route table with a custom subnet route table.
- You can add, remove, and modify routes in the main route table.
- You can explicitly associate a subnet with the main route table, even if it's already implicitly associated.

#### Custom route tables

The main route table is used implicitly by subnets that do not have an explicit route table association. However, you might want to provide different routes on a per-subnet basis for traffic to access resources outside of the VPC.

If you associate a subnet with a custom route table, the subnet will use it instead of the main route table. 

Each custom route table that you create will have the local route already inside it, allowing communication to flow between all resources and subnets inside the VPC.

![By associating subnets with a custom route table, the subnets will use the custom route table instead of the main route table.](./assets/M8feNhlriCQ2dfM7_za27r6BRGtbQqnc3.png)

### Network ACLs

A network ACL is a virtual firewall that controls inbound and outbound traffic at the subnet level.

By default, your accountâs default network ACL allows all inbound and outbound traffic

Network ACLs perform **stateless** packet filtering. They remember nothing and check packets that cross the subnet border each way: inbound and outbound. When a packet response for that request comes back to the subnet, the network ACL does not remember your previous request. The network ACL checks the packet response against its list of rules to determine whether to allow or deny.

### Security Groups

A security group is a virtual firewall that controls inbound and outbound traffic for an Amazon EC2 instance.



<img src="./assets/3Nn7qLAZ6WgGbXvV_s3gZMSNIJWunc8qs.png" alt="Security group firewall protecting an Amazon EC2 instance." style="zoom:25%;" />

By default, a security group denies all inbound traffic and allows all outbound traffic. You can add custom rules to configure which traffic should be allowed; any other traffic would then be denied.

If you have multiple Amazon EC2 instances within the same VPC, you can associate them with the same security group or use different security groups for each instance. 

In AWS Security Groups, you cannot explicitly deny traffic. Security groups are stateful and work on a whitelist model, meaning you can only define rules that allow traffic. 

Security groups perform **stateful** packet filtering. They remember previous decisions made for incoming packets.When a packet response for that request returns to the instance, the security group remembers your previous request. The security group allows the response to proceed, regardless of inbound security group rules.

![img](./assets/Uni67QSBrWsNLxsc_ha8um-1InZb0jryB.png)

### Amazon Route 53

[**Amazon Route 53**(opens in a new tab)](https://aws.amazon.com/route53) is a DNS web service. It gives developers and businesses a reliable way to route end users to internet applications hosted in AWS. 

Another feature of Route 53 is the ability to manage the DNS records for domain names. You can register new domain names directly in Route 53. You can also transfer DNS records for existing domain names managed by other domain registrars. This enables you to manage all of your domain names within a single location.

## Module 5 Storage and Databases

### Instance stores

Block-level storage volumes behave like physical hard drives.

An [**instance store**(opens in a new tab)](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html) provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance. When the instance is terminated, you lose any data in the instance store.

### Amazon Elastic Block Store (Amazon EBS)

This is corresponding to local machine's external SSD/HDD.

This is availability zone resilient service

[**Amazon Elastic Block Store (Amazon EBS)**(opens in a new tab)](https://aws.amazon.com/ebs) is a service that provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all the data on the attached EBS volume remains available.

To create an EBS volume, you define the configuration (such as volume size and type) and provision it. After you create an EBS volume, it can attach to an Amazon EC2 instance.

Because EBS volumes are for data that needs to persist, itâs important to back up the data. You can take **incremental** backups of EBS volumes by creating Amazon EBS snapshots.

![img](./assets/F8QjUBkmYQcjayMX_ruyKsXvVP8ZbeHC1.png)

### Object storage



![img](./assets/qntupRGwR-wR8Taf_OudEOAamSBQ6zv19.png)



In **object storage**, each object consists of data, metadata, and a key.

The data might be an image, video, text document, or any other type of file. Metadata contains information about what the data is, how it is used, the object size, and so on. An objectâs key is its unique identifier.

Recall that when you modify a file in block storage, only the pieces that are changed are updated. When a file in object storage is modified, the entire object is updated.

### Amazon Simple Storage Service (Amazon S3)

[**Amazon Simple Storage Service (Amazon S3)**(opens in a new tab)](https://aws.amazon.com/s3/) is a service that provides object-level storage. Amazon S3 stores data as objects in buckets.

You can upload any type of file to Amazon S3, such as images, videos, text files, and so on. For example, you might use Amazon S3 to store backup files, media files for a website, or archived documents. Amazon S3 offers unlimited storage space. The maximum file size for an object in Amazon S3 is 5 TB.

When you upload a file to Amazon S3, you can set permissions to control visibility and access to it. You can also use the Amazon S3 versioning feature to track changes to your objects over time.

#### Bucket

In Amazon S3, you store your objects in containers called buckets. You canât upload an object, not even a single photo, to Amazon S3 without creating a bucket first. When you store an object in a bucket, the combination of a bucket name, key, and version ID uniquely identifies the object.  

You can configure bucket policy so that only certain IAM role can access this bucket.

Bucket name should be unique. It works like a URL to your domain

#### Amazon S3 storage classes

##### S3 Standard

- Designed for frequently accessed data
- Stores data in a minimum of three Availability Zones
- This does not have retreival fee

##### S3 Standard-Infrequent Access (S3 Standard IA)

- Ideal for infrequently accessed data
- Performance is as good as S3 standard and is cheaper than standard. But this requires retrieval fee

##### S3 One Zone-Infrequent Access (S3 One Zone IA)

- Stores data in a single Availability Zone (**can lose data**)
- Has a lower storage price than Amazon S3 Standard-IA

##### S3 Intelligient Tiering

- Ideal for data with unknown or changing access patterns
- Requires a small monthly monitoring and automation fee per object

In the S3 Intelligent-Tiering storage class, Amazon S3 monitors objectsâ access patterns. If you havenât accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.

##### S3 Glacier Instant Retrieval

- Works well for archived data that requires immediate access
- Can retrieve objects within a few milliseconds

When you decide between the options for archival storage, consider how quickly you must retrieve the archived objects. You can retrieve objects stored in the S3 Glacier Instant Retrieval storage class within milliseconds, with the same performance as S3 Standard. Compared to IA, it has longer minimum storage duration.

##### S3 Flexible Retrieval

- Low-cost storage designed for data archiving
- Able to retrieve objects within a few minutes to hours

##### S3 Glacier Deep Archive

- Lowest-cost object storage class ideal for archiving
- Able to retrieve objects within 12 hours

##### S3 Outposts

- Creates S3 buckets on Amazon S3 Outposts
- Makes it easier to retrieve, store, and access data on AWS Outposts

Amazon S3 Outposts delivers object storage to your on-premises AWS Outposts environment. Amazon S3 Outposts is designed to store data durably and redundantly across multiple devices and servers on your Outposts. It works well for workloads with local data residency requirements that must satisfy demanding performance needs by keeping data close to on-premises applications.

#### Versioning

If you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object. Similar to git, by using versioning-enabled buckets, you can recover objects from accidental deletion or overwrite.

Buckets can be in one of three states: unversioned (default), Versioning-enabled, Versioning-suspended (new change would not be versioned but old changes' versioning still exists)

#### Managing your storage lifecycle

If you keep manually changing your objects, such as your employee photos, from storage tier to storage tier, you might want to automate the process by configuring their Amazon S3 lifecycle. When you define a lifecycle configuration for an object or group of objects, you can choose to automate between two types of actions: transition and expiration.

- **Transition actions** define when objects should transition to another storage class.
- **Expiration actions** define when objects expire and should be permanently deleted.

### Amazon EBS V.S. Amazon S3

Assume you have 80 GB file that can be updated frequently. Then EBS would be a good option because you update part of the file. If S3 is used, then even if you channge only one bit of the file, you have to re-upload the whole 80GB file again

If your file is mandatory, i.e. once stored, it's never or rarely updated. Then S3 would be a good choice. Because it's:

- web-enabled: each file already has a URL
- region-distributed: no need to do backup to avoid data loss

### File storage

In **file storage**, multiple clients (such as users, applications, servers, and so on) can access data that is stored in shared file folders. In this approach, a storage server uses block storage with a local file system to organize files. Clients access data through file paths.

### Amazon Elastic File System (Amazon EFS)

This is corresponding to NAS in on-premises data center. This is regional service

[**Amazon Elastic File System (Amazon EFS)**(opens in a new tab)](https://aws.amazon.com/efs/) is a scalable file system used with AWS Cloud services and on-premises resources. As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications

### Amazon EFS V.S. Amazon EBS

An Amazon EBS volume stores data in a **single** Availability Zone. To attach an Amazon EC2 instance to an EBS volume, both the Amazon EC2 instance and the EBS volume must reside within the same Availability Zone.

Amazon EFS is a regional service. It stores data in and across **multiple** Availability Zones. The duplicate storage enables you to access data concurrently from all the Availability Zones in the Region where a file system is located. Additionally, on-premises servers can access Amazon EFS using AWS Direct Connect.

EFS automatically scales up its capacity but EBS does not

### Amazon FSx V.S. EFS

- **Use Case & Integration**: EFS is more general-purpose and cloud-native, while FSx is specialized for certain systems (Windows, high-performance computing).
- **Performance**: FSx, especially FSx for Lustre, is designed for higher performance requirements.
- **File System Compatibility**: EFS is more suited for Linux/Unix environments, while FSx offers solutions for both Windows and high-performance computing environments.
- **Pricing Model**: EFS has a pay-as-you-go model based on used storage, while FSx pricing can vary more based on the specific service and configuration options.

### Lustre

Lustre is a type of parallel distributed file system, primarily used for large-scale cluster computing. It's widely adopted in environments requiring high performance and large data throughput, such as in high-performance computing (HPC), large-scale scientific simulations, and data-intensive workloads. 

### AWS Storage Gateway

AWS Storage Gateway is a hybrid cloud storage service that enables on-premises environments to seamlessly use AWS cloud storage. It bridges on-premises IT environments with cloud storage for backup, archiving, disaster recovery, and more. Key components and features include:

- **Types of Storage Gateways**:
  - **File Gateway**: Provides a file interface to S3, allowing storage and retrieval of files as objects.
  - **Volume Gateway:**
    - **Stored Volumes**: Store all data on-premises and asynchronously back up to S3.
    - **Cached Volumes**: Store primary data in S3 and retain frequently accessed data on-premises.
  - **Tape Gateway**: Emulates physical tape infrastructure for archiving and backup purposes, storing data on virtual tapes in AWS.
- **Integration with AWS Services**: Seamlessly integrates with S3, Glacier, and EBS Snapshot services.
- **Data Transfer**:
  - Offers efficient data transfer to AWS, optimizing network bandwidth.
  - Supports encryption of data in transit and at rest.
- **Hybrid Use Cases**:
  - Ideal for hybrid cloud storage architectures.
  - Commonly used for backup and disaster recovery, data archiving, and tiered storage.
- **Management and Monitoring**: Can be managed through the AWS Management Console, allowing easy monitoring and configuration.

### Amazon Relational Database Service

[**Amazon Relational Database Service (Amazon RDS)**(opens in a new tab)](https://aws.amazon.com/rds/) is a service that enables you to run relational databases in the AWS Cloud.

Amazon RDS is a managed service that automates tasks such as hardware provisioning, database setup, patching, and backups. With these capabilities, you can spend less time completing administrative tasks and more time using data to innovate your applications. You can integrate Amazon RDS with other services to fulfill your business and operational needs, such as using AWS Lambda to query your database from a serverless application.

Amazon RDS provides a number of different security options. Many Amazon RDS database engines offer encryption at rest (protecting data while it is stored) and encryption in transit (protecting data while it is being sent and received).

Amazon RDS is available on six database engines, which optimize for memory, performance, or input/output (I/O). Supported database engines include:

- Amazon Aurora
- PostgreSQL
- MySQL
- MariaDB
- Oracle Database
- Microsoft SQL Server

#### RDS Database Instance

Just like the databases you build and manage yourself, Amazon RDS is built from compute and storage.

Underneath the DB instance is an EC2 instance. However, this instance is managed through the Amazon RDS console instead of the Amazon EC2 console.

The storage portion of DB instances for Amazon RDS use Amazon Elastic Block Store (Amazon EBS) volumes for database and log storage.

When using Aurora, data is stored in cluster volumes, which are single, virtual volumes that use solid-state drives (SSDs). A cluster volume contains copies of your data across three Availability Zones in a single AWS Region. For nonpersistent, temporary files, Aurora uses local storage.

#### Backup data

You donât want to lose your data. To take regular backups of your Amazon RDS instance, you can use automated backups or manual snapshots.

#### Redundancy with Amazon RDS Multi-AZ

In an Amazon RDS Multi-AZ deployment, Amazon RDS creates a redundant copy of your database in another Availability Zone. You end up with two copies of your databaseâa primary copy in a subnet in one Availability Zone and a standby copy in a subnet in a second Availability Zone.

The primary copy of your database provides access to your data so that applications can query and display the information. The data in the primary copy is synchronously replicated to the standby copy. The standby copy is not considered an active database, and it does not get queried by applications.



![Diagram depicting Amazon RDS Multi-AZ creating a redundant copy of a database in another Availability Zone.](./assets/uH2dbGPLi5h5x4Xk_427K0gUGe81kqVaq.png)

To improve availability, Amazon RDS Multi-AZ ensures that you have two copies of your database running and that one of them is in the primary role. If an availability issue arises, such as the primary database loses connectivity, Amazon RDS initiates an automatic failover.

When you create a DB instance, a Domain Name System (DNS) name is provided. AWS uses that DNS name to fail over to the standby database. In an automatic failover, the standby database is promoted to the primary role, and queries are redirected to the new primary database.

To help ensure that you don't lose Multi-AZ configuration, there are two ways you can create a new standby database. They are as follows:

- Demote the previous primary to standby if it's still up and running.
- Stand up a new standby DB instance.

The reason you can select multiple subnets for an Amazon RDS database is because of the Multi-AZ configuration. You will want to ensure that you have subnets in different Availability Zones for your primary and standby copies.

##### Read replication instance

When Multi-AZ is enabled in AWS RDS, setting up a read replica can be useful, and asynchronous replication is typically used for this purpose. Here's why:

1. **Usefulness of Read Replicas:**
   - **Load Balancing:** Read replicas allow you to offload read traffic from your primary database, which can be particularly beneficial for read-heavy workloads.
   - **Improved Performance:** By directing read queries to replicas, you can reduce the load on the primary database, thereby improving its performance for write operations.
   - **Reporting and Analytics:** Replicas can be used for running reporting queries or analytics, ensuring that these operations do not affect the primary databaseâs performance.
   - **Disaster Recovery:** In some configurations, a read replica can be promoted to a primary database in case of a failure, enhancing your disaster recovery strategy.
2. **Use of Asynchronous Replication:**
   - **Minimized Impact on Primary Database:** Asynchronous replication reduces the performance impact on the primary database, as it does not need to wait for the replica to acknowledge the write operations.
   - **Higher Throughput:** It allows for higher write throughput on the primary database, as the replication process does not block the primary database operations.
   - **Latency Considerations:** While there can be a slight lag in data synchronization between the primary and the replica, this is typically acceptable for scenarios where read replicas are used (like reporting or handling read-only traffic).

In summary, read replicas in AWS RDS enhance scalability and performance by distributing the database load, particularly for read-intensive operations, while asynchronous replication is chosen for its efficiency and minimal impact on the primary database's performance.

### Amazon Aurora

[**Amazon Aurora**(opens in a new tab)](https://aws.amazon.com/rds/aurora/) is an enterprise-class relational database. It is compatible with MySQL and PostgreSQL relational databases. It is up to five times faster than standard MySQL databases and up to three times faster than standard PostgreSQL databases.

Amazon Aurora helps to reduce your database costs by reducing unnecessary input/output (I/O) operations, while ensuring that your database resources remain reliable and available. 

Consider Amazon Aurora if your workloads require high availability. It replicates six copies of your data across three Availability Zones and continuously backs up your data to Amazon S3.

### Amazon DynamoDB

[**Amazon DynamoDB**(opens in a new tab)](https://aws.amazon.com/dynamodb/) is a key-value database service. It delivers single-digit millisecond performance at any scale.

#### Serverless

DynamoDB is serverless, which means that you do not have to provision, patch, or manage servers. 

You also do not have to install, maintain, or operate software.

#### Automatic Scaling

As the size of your database shrinks or grows, DynamoDB automatically scales to adjust for changes in capacity while maintaining consistent performance. 

This makes it a suitable choice for use cases that require high performance while scaling.

### Amazon Redshift

[**Amazon Redshift**(opens in a new tab)](https://aws.amazon.com/redshift) is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and helps you to understand relationships and trends across your data.

It's column-based rather than row-based

### AWS Data Sync

AWS DataSync is a managed data transfer service that simplifies, automates, and accelerates moving data between on-premises storage systems and AWS storage services, as well as between different AWS storage services. Hereâs a brief introduction:

1. **Efficient Data Transfer:** Optimizes data transfer over the network, offering high-speed performance that can scale to meet large data migration and transfer needs.
2. **Automated and Managed:** Automates many of the tasks related to data transfers, like data conversion, scheduling, monitoring, and validation, reducing manual effort and complexity.
3. **Secure:** DataSync uses encryption and other security features to ensure that your data is protected during transit.
4. **Wide Compatibility:** Supports transferring data to and from various AWS services like Amazon S3, Amazon EFS, and Amazon FSx for Windows File Server, and it can connect to NFS and SMB file systems.
5. **Use Cases:** Ideal for migrating active datasets to AWS, transferring data to and from the cloud for analytical processing, and ongoing data replication for disaster recovery or backup purposes.
6. **Cost-Effective:** Charges are based on the amount of data transferred, without upfront costs or infrastructure to manage.

AWS DataSync is useful for businesses that need a quick, secure, and easy way to move large amounts of data to the AWS cloud or between AWS storage services.

### AWS Database Migration Service (AWS DMS)

[**AWS Database Migration Service (AWS DMS)**(opens in a new tab)](https://aws.amazon.com/dms/) enables you to migrate relational databases, nonrelational databases, and other types of data stores.

With AWS DMS, you move data between a source database and a target database. [The source and target databases(opens in a new tab)](https://aws.amazon.com/dms/resources) can be of the same type or different types. During the migration, your source database remains operational, reducing downtime for any applications that rely on the database. 

It can also be used for other purposes:

- Developent and test database migration: Enabling developers to test applications against production data without affecting production users
- Database consolidation: Combining several databases into a single database
- Continuous replication: Sending ongoing copies of your data to other target sources instead of doing a one-time migration

### Additional Database Services

#### Amazon DocumentDB

[**Amazon DocumentDB**(opens in a new tab)](https://aws.amazon.com/documentdb) is a document database service that supports MongoDB workloads. (MongoDB is a document database program.)

#### Amazon Neptune

[**Amazon Neptune**(opens in a new tab)](https://aws.amazon.com/neptune) is a graph database service. 

You can use Amazon Neptune to build and run applications that work with highly connected datasets, such as recommendation engines, fraud detection, and knowledge graphs.

#### Amazon Quantum Ledger Database (Amazon QLDB)

[**Amazon Quantum Ledger Database (Amazon QLDB)**(opens in a new tab)](https://aws.amazon.com/qldb) is a ledger database service. 

You can use Amazon QLDB to review a complete history of all the changes that have been made to your application data.

#### Amazon Managed Blockchain

[**Amazon Managed Blockchain**(opens in a new tab)](https://aws.amazon.com/managed-blockchain) is a service that you can use to create and manage blockchain networks with open-source frameworks. 

Blockchain is a distributed ledger system that lets multiple parties run transactions and share data without a central authority.

#### Amazon ElastiCache

[**Amazon ElastiCache**(opens in a new tab)](https://aws.amazon.com/elasticache) is a service that adds caching layers on top of your databases to help improve the read times of common requests. 

It supports two types of data stores: Redis and Memcached.

#### Amazon DynamoDB Accelerator

[**Amazon DynamoDB Accelerator (DAX)**(opens in a new tab)](https://aws.amazon.com/dynamodb/dax/) is an in-memory cache for DynamoDB. 

It helps improve response times from single-digit milliseconds to microseconds.

## Module 6 Security

### The AWS shared responsibility model

The shared responsibility model divides into customer responsibilities (commonly referred to as âsecurity in the cloudâ) and AWS responsibilities (commonly referred to as âsecurity of the cloudâ).

### Root User

When you first create an AWS account, you begin with a single sign-in identity that has complete access to all AWS services and resources in the account. This identity is called the AWS root user and is accessed by signing in with the email address and password that were used to create the account. 

Access keys allow you to make programmatic requests from the AWS Command Line Interface (AWS CLI) or AWS API.

Access keys consist of two parts:

- **Access key ID:** for example, ***A2lAl5EXAMPLE***
- **Secret access key:** for example, ***wJalrFE/KbEKxE***

![img](./assets/6jTnHGzFpim42ZCZ_YD5J2pBrmA9lGqT-.png)

### AWS Identity and Access Management (IAM)

[**AWS Identity and Access Management (IAM)**(opens in a new tab)](https://aws.amazon.com/iam/) enables you to manage access to AWS services and resources securely.  

IAM gives you the flexibility to configure access based on your companyâs specific operational and security needs. You do this by using a combination of IAM features, which are explored in detail in this lesson:

- IAM users, groups, and roles
- IAM policies
- Multi-factor authentication

#### IAM users

An **IAM user** is an identity that you create in AWS. It represents the person or application that interacts with AWS services and resources. It consists of a name and credentials.

By default, when you create a new IAM user in AWS, it has no permissions associated with it

#### IAM policies

An **IAM** **policy** is a document that allows or denies permissions to AWS services and resources.  

IAM policies enable you to customize usersâ levels of access to resources. For example, you can allow users to access all of the Amazon S3 buckets within your AWS account, or only a specific bucket.

<img src="./assets/esK5ZV2SuWHsdoNx_vKf8uGbqJDqmoCNE.png" alt="Example of an IAM policy" style="zoom:50%;" />

This example IAM policy allows permission to access the objects in the Amazon S3 bucket with ID: *AWSDOC-EXAMPLE-BUCKET*.

##### AWS managed policies

An *AWS managed policy* is a standalone policy that is created and administered by AWS. *Standalone policy* means that the policy has its own Amazon Resource Name (ARN) that includes the policy name

##### Customer managed policies

You can create standalone policies in your own AWS account that you can attach to principal entities (users, groups, and roles). 

##### Inline policies

An inline policy is a policy created for a single IAM identity (a user, group, or role). Inline policies maintain a strict one-to-one relationship between a policy and an identity. They are deleted when you delete the identity. 

#### IAM groups

An IAM group is a collection of IAM users. When you assign an IAM policy to a group, all users in the group are granted permissions specified by the policy.

#### IAM roles

An IAM role is an identity that you can assume to gain temporary access to permissions.  

Before an IAM user, application, or service can assume an IAM role, they must be granted permissions to switch to the role. When someone assumes an IAM role, they abandon all previous permissions that they had under a previous role and assume the permissions of the new role. 

Temporary security credentials generated by AWS IAM roles consist of the following components:

1. **Access Key ID:** Similar to a username, it's part of the credentials to authenticate requests.
2. **Secret Access Key:** Similar to a password, used in conjunction with the Access Key ID.
3. **Session Token:** A token required in addition to the Access Key ID and Secret Access Key for increased security.

Best practice:

IAM roles are ideal for situations in which access to services or resources needs to be granted temporarily, instead of long-term.  

##### Understanding AWS Role Assumption in Context of JWT Access Tokens

AWS role assumption in Amazon Web Services (AWS) aligns with the concept of JWT (JSON Web Tokens) access tokens, focusing on secure, temporary access to AWS resources.

###### Similarities with JWT Access Tokens

- **Temporary Credentials**: Like JWT tokens, assuming an AWS role provides temporary security credentials.
- **Limited Lifetime**: These credentials have a limited lifetime, similar to the time-bound validity of JWT tokens.

###### Key Aspects of AWS Role Assumption

1. **Role Creation and Trust Policy**: An IAM role is created with specific permissions. The roleâs trust policy dictates who can assume it, akin to how an authentication server governs JWT token issuance.
   1. You can attach specific role to an EC2 instance when creating EC2 instance
2. **Assume Role via AWS STS**: Temporary security credentials are obtained by assuming the role through the AWS STS (Security Token Service), similar to how a user receives a JWT token after authentication.
3. **Expiration and Renewal**: Just like JWT tokens, these AWS credentials must be renewed after their expiration.

###### Usage Scenarios

- **Cross-Account Access**: AWS roles can be assumed by users from different AWS accounts, similar to how JWT tokens enable access across various services.
- **Federation**: In federated scenarios, AWS roles can be assumed, paralleling JWT tokens in federated identity systems.

### Identity Provider

If you decide to make your cat photo application into a business and begin to have more than a handful of people working on it, consider managing employee identity information through an identity provider (IdP). Using an IdP, whether it's with an AWS service such as AWS IAM Identity Center (successor to AWS Single Sign-On) or a third-party identity provider, provides a single source of truth for all identities in your organization.

You no longer have to create separate IAM users in AWS. You can instead use IAM roles to provide permissions to identities that are *federated* from your IdP. Being federated is a process that allows for the transfer of identity and authentication information across a set of networked systems. 

For example, your employee Martha has access to multiple AWS accounts. Instead of creating and managing multiple IAM users named Martha in each of those AWS accounts, you could manage Martha in your companyâs IdP. If Martha moves in the company or leaves the company, Martha can be updated in the IdP rather than in every AWS account in the company.

### AWS Organizations

Suppose that your company has multiple AWS accounts. You can use [**AWS Organizations**(opens in a new tab)](https://aws.amazon.com/organizations) to consolidate and manage multiple AWS accounts within a central location.

When you create an organization, AWS Organizations automatically creates a **root**, which is the parent container for all the accounts in your organization. 

Consolidated billing is another feature of AWS Organizations. You will learn about consolidated billing in a later module.

#### Service control policies (SCPs)

In AWS Organizations, you can centrally control permissions for the accounts in your organization by using [**service control policies (SCPs)**(opens in a new tab)](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html). SCPs enable you to place restrictions on the AWS services, resources, and individual API actions that users and roles in each account can access.

SCPs are similar to AWS Identity and Access Management (IAM) permission policies and use almost the same syntax. However, an SCP never grants permissions. Instead, SCPs are JSON policies that specify the maximum permissions for the affected accounts. 

#### Explanation from ChatGPT

In AWS, an Identity Provider (IdP) is like a security guard at the entrance of a building (AWS). This security guard doesn't work directly for the building but is trusted by it.

1. **Job of IdP**: When someone (a user) wants to enter the building (use AWS services), they show their ID (credentials) to this security guard (IdP). The guard checks if the ID is valid and tells the building who this person is and if they should be allowed in.
2. **Federation**: Imagine people from a partner company need to enter your building frequently. Instead of issuing them new IDs, your building trusts the IDs given by their company. This is like federation in AWS, where AWS trusts an external system's verification of users.
3. **Types of IDs Accepted**: AWS's IdP can understand two types of IDs â SAML (a standard format for exchanging authentication information) and OpenID Connect (another format, used for web-based authentication).
4. **Roles in AWS**: In AWS, you donât give permissions to each person directly. Instead, you assign permissions to roles (like job titles in a company). When the IdP tells AWS who the person is, AWS lets them assume a role with certain permissions.
5. **Integration with Other Companies**: AWS can work with various external IdPs like Okta or Microsoft Active Directory. This means AWS can trust the IDs issued by these external systems.
6. **AWS's Own IdP Services**: AWS offers services like IAM Identity Center and AWS Directory Service. These are like AWS having its own team to issue IDs and manage who can enter the building.

So, an Identity Provider in AWS is essentially a trusted system that verifies who someone is and what they can do in AWS, based on their identity. This is especially useful for companies that want to use their existing systems to manage access to AWS.

#### Organizational units

In AWS Organizations, you can group accounts into organizational units (OUs) to make it easier to manage accounts with similar business or security requirements. When you apply a policy to an OU, all the accounts in the OU automatically inherit the permissions specified in the policy.  

### Compliance

#### AWS Artifact

Depending on your companyâs industry, you may need to uphold specific standards. An audit or inspection will ensure that the company has met those standards.

[**AWS Artifact**(opens in a new tab)](https://aws.amazon.com/artifact) is a service that provides on-demand access to AWS security and compliance reports and select online agreements. AWS Artifact consists of two main sections: AWS Artifact Agreements and AWS Artifact Reports.

#### Customer Compliance Center

The [**Customer Compliance Center**(opens in a new tab)](https://aws.amazon.com/compliance/customer-center/) contains resources to help you learn more about AWS compliance. 

In the Customer Compliance Center, you can read customer compliance stories to discover how companies in regulated industries have solved various compliance, governance, and audit challenges.

### AWS Shield for DDoS attack

AWS Shield is a service that protects applications against DDoS attacks. AWS Shield provides two levels of protection: Standard and Advanced.

#### AWS Shield Standard

**AWS Shield Standard** automatically protects all AWS customers at no cost. It protects your AWS resources from the most common, frequently occurring types of DDoS attacks. 

As network traffic comes into your applications, AWS Shield Standard uses a variety of analysis techniques to detect malicious traffic in real time and automatically mitigates it. 

#### AWS Shield Advanced

**AWS Shield Advanced** is a paid service that provides detailed attack diagnostics and the ability to detect and mitigate sophisticated DDoS attacks. 

It also integrates with other services such as Amazon CloudFront, Amazon Route 53, and Elastic Load Balancing. Additionally, you can integrate AWS Shield with AWS WAF by writing custom rules to mitigate complex DDoS attacks.

### AWS Key Management Service (AWS KMS)

You must ensure that your applicationsâ data is secure while in storage **(encryption at rest)** and while it is transmitted, known as **encryption in transit**.

[**AWS Key Management Service (AWS KMS)**(opens in a new tab)](https://aws.amazon.com/kms) enables you to perform encryption operations through the use of **cryptographic keys**. A cryptographic key is a random string of digits used for locking (encrypting) and unlocking (decrypting) data. You can use AWS KMS to create, manage, and use cryptographic keys. You can also control the use of keys across a wide range of services and in your applications.

With AWS KMS, you can choose the specific levels of access control that you need for your keys. For example, you can specify which IAM users and roles are able to manage keys. Alternatively, you can temporarily disable keys so that they are no longer in use by anyone. Your keys never leave AWS KMS, and you are always in control of them.

### AWS WAF

[**AWS WAF**(opens in a new tab)](https://aws.amazon.com/waf) is a web application firewall that lets you monitor network requests that come into your web applications. 

WAF uses a [**web access control list (ACL)**(opens in a new tab)](https://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html) to protect your AWS resources. 

### Amazon Inspector

Amazon Inspector helps to improve the security and compliance of applications by running automated security assessments. It checks applications for security vulnerabilities and deviations from security best practices, such as open access to Amazon EC2 instances and installations of vulnerable software versions. 

#### Difference with trusted advisor

AWS Inspector and AWS Trusted Advisor are two different services provided by Amazon Web Services, each serving distinct purposes:

1. **AWS Inspector:**
   - **Purpose:** Focuses on security and compliance.
   - **Functionality:** Automatically assesses applications for vulnerabilities or deviations from best practices. It's used primarily for security assessments of EC2 instances and the applications running on them.
   - **Scope:** Checks for network security, host security, and known vulnerabilities and exposures in your EC2 instances and the software installed on them.
   - **Use Case:** Helps in identifying security issues like open ports, exposed sensitive data, or non-compliance with security standards.
2. **AWS Trusted Advisor:**
   - **Purpose:** Provides recommendations across various categories.
   - **Functionality:** Offers advice on cost optimization, performance, security, and fault tolerance to help you follow AWS best practices.
   - **Scope:** Covers a broader range of AWS services beyond EC2 and offers insights into resource utilization, service limits, etc.
   - **Use Case:** Helps in optimizing AWS environments, identifying cost-saving opportunities, and improving system performance and reliability.

In summary, AWS Inspector is more focused on security and compliance of your EC2 instances, while AWS Trusted Advisor provides a broader range of advice on optimizing your entire AWS environment.

### Amazon GuardDuty

[**Amazon GuardDuty**(opens in a new tab)](https://aws.amazon.com/guardduty) is a service that provides intelligent threat detection for your AWS infrastructure and resources. It identifies threats by continuously monitoring the network activity and account behavior within your AWS environment.

## Module 7 Monitoring and Analytics

### Amazon CloudWatch

[**Amazon CloudWatch**(opens in a new tab)](https://aws.amazon.com/cloudwatch/) is a web service that enables you to monitor and manage various metrics and configure alarm actions based on data from those metrics.

CloudWatch uses [**metrics**(opens in a new tab)](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html) to represent the data points for your resources. AWS services send metrics to CloudWatch. CloudWatch then uses these metrics to create graphs automatically that show how performance has changed over time. 

#### CloudWatch dashboard

![CloudWatch dashboard showing metrics for Amazon RDS, Amazon EC2, and Amazon EBS](./assets/soUHIPDRwFlque1l_rLfuExSsSpuXOVqf.png)



The CloudWatch [**dashboard**(opens in a new tab)](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards.html) feature enables you to access all the metrics for your resources from a single location. For example, you can use a CloudWatch dashboard to monitor the CPU utilization of an Amazon EC2 instance, the total number of requests made to an Amazon S3 bucket, and more. You can even customize separate dashboards for different business purposes, applications, or resources.

#### Alarm

You can define an alarm to be triggered based on certain metrics (e.g. CPU over 70% for 5 minutes). And you make it send emails when alarm is triggered.

An alam has 3 possible states:

- OK
- Alarm
- Insufficient Data

You can even set up an alarm to invoke an Amazon SNS notification that invokes a Lambda function. The Lambda function then calls any AWS API to manage your resources and troubleshoot operational issues. 

#### Basic & detaild monitoring

Basic monitoring is free and report a data point per metric per 5 minute. While details monitoring (paid) can publish every minute

#### Metrics

 A metric represents a time-ordered set of data points that are published to CloudWatch. Think of a metric as a variable to monitor and the data points as representing the values of that variable over time. Every metric data point must be associated with a timestamp.

AWS services that send data to CloudWatch attach dimensions to each metric. A dimension is a name and value pair that is part of the metric

#### Custom metrics

You can create your own application metrics and send to AWS cloud watch.

#### Amazon CloudWatch Logs

CloudWatch Logs is centralized place for logs to be stored and analyzed. 

- Log Event: A log event is a record of activity recorded by the application or resource being monitored. It has a timestamp and an event message.
- Log Stream: Log events are grouped into log streams, which are sequences of log events that all belong to the same resource being monitored. 
- Log Group: A log group is composed of log streams that all share the same retention and permissions settings. 
  - For example, suppose you have multiple EC2 instances hosting your application and you send application log data to CloudWatch Logs. You can group the log streams from each instance into one log group. 

![Some of the concepts that make up a CloudWatch Log are log events, log streams, and log groups.](./assets/24fhfSwVQMaLqNxH_FccH7Z7TkEVBdO-V.png)

### AWS CloudTrail

[**AWS CloudTrail**(opens in a new tab)](https://aws.amazon.com/cloudtrail/) records API calls for your account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, and more. You can think of CloudTrail as a âtrailâ of breadcrumbs (or a log of actions) that someone has left behind them.

Events are typically updated in CloudTrail within 15 minutes after an API call.

#### CloudTrail Insights

Within CloudTrail, you can also enable [**CloudTrail Insights**(opens in a new tab)](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-insights-events-with-cloudtrail.html). This optional feature allows CloudTrail to automatically detect unusual API activities in your AWS account. 

For example, CloudTrail Insights might detect that a higher number of Amazon EC2 instances than usual have recently launched in your account. You can then review the full event details to determine which actions you need to take next.

### AWS Trusted Advisor

[**AWS Trusted Advisor**(opens in a new tab)](https://aws.amazon.com/premiumsupport/technology/trusted-advisor/) is a web service that inspects your AWS environment and provides real-time recommendations in accordance with AWS best practices.

Trusted Advisor compares its findings to AWS best practices in five categories: cost optimization, performance, security, fault tolerance, and service limits. For the checks in each category, Trusted Advisor offers a list of recommended actions and additional resources to learn more about AWS best practices. 

The guidance provided by AWS Trusted Advisor can benefit your company at all stages of deployment. For example, you can use AWS Trusted Advisor to assist you while you are creating new workflows and developing new applications. You can also use it while you are making ongoing improvements to existing applications and resources.

#### AWS Trusted Advisor dashboard



![AWS Trusted Advisor dashboard where the number of problems, investigations, and actions is indicated for each category.](./assets/GS8__RI_kUsr0oXB_2gGWhu3Np9FWdzHm.jpg)



When you access the Trusted Advisor dashboard on the AWS Management Console, you can review completed checks for cost optimization, performance, security, fault tolerance, and service limits.

For each category:

- The green check indicates the number of items for which it detected **no problems**.

- The orange triangle represents the number of recommended **investigations**.

  The red circle represents the number of recommended **actions**.

## Moduel 8 Pricing and Support

### AWS Free Tier

The [AWS Free Tier(opens in a new tab)](https://aws.amazon.com/free/) enables you to begin using certain services without having to worry about incurring costs for the specified period. 

Three types of offers are available: 

- Always Free
- 12 Months Free
- Trials

### How AWS pricing works

AWS offers a range of cloud computing services with pay-as-you-go pricing. 

#### Pay for what you use

For each service, you pay for exactly the amount of resources that you actually use, without requiring long-term contracts or complex licensing. 

#### Pay less when you reserve

Some services offer reservation options that provide a significant discount compared to On-Demand Instance pricing.

For example, suppose that your company is using Amazon EC2 instances for a workload that needs to run continuously. You might choose to run this workload on Amazon EC2 Instance Savings Plans, because the plan allows you to save up to 72% over the equivalent On-Demand Instance capacity.

#### Pay less with volume-based discounts when you use more

Some services offer tiered pricing, so the per-unit cost is incrementally lower with increased usage.

For example, the more Amazon S3 storage space you use, the less you pay for it per GB.

### AWS Pricing Calculator

The [**AWS Pricing Calculator**(opens in a new tab)](https://calculator.aws/#/) lets you explore AWS services and create an estimate for the cost of your use cases on AWS. You can organize your AWS estimates by groups that you define. A group can reflect how your company is organized, such as providing estimates by cost center.

### AWS pricing examples

This section presents a few examples of pricing in AWS services. 

#### AWS Lambda

For AWS Lambda, you are charged based on the number of requests for your functions and the time that it takes for them to run.

AWS Lambda allows 1 million free requests and up to 3.2 million seconds of compute time per month.

You can save on AWS Lambda costs by signing up for a Compute Savings Plan. A Compute Savings Plan offers lower compute costs in exchange for committing to a consistent amount of usage over a 1-year or 3-year term. This is an example of **paying less when you reserve**. 

#### Amazon EC2

With Amazon EC2, you pay for only the compute time that you use while your instances are running.

For some workloads, you can significantly reduce Amazon EC2 costs by using Spot Instances. For example, suppose that you are running a batch processing job that is able to withstand interruptions. Using a Spot Instance would provide you with up to 90% cost savings while still meeting the availability requirements of your workload.

 You can find additional cost savings for Amazon EC2 by considering Savings Plans and Reserved Instances.

### AWS Billing & Cost Management dashboard

Use the [**AWS Billing & Cost Management dashboard**(opens in a new tab)](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html) to pay your AWS bill, monitor your usage, and analyze and control your costs.

- Compare your current month-to-date balance with the previous month, and get a forecast of the next month based on current usage.
- View month-to-date spend by service.
- View Free Tier usage by service.
- Access Cost Explorer and create budgets.
- Purchase and manage Savings Plans.
- Publish [AWS Cost and Usage Reports(opens in a new tab)](https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html).

### Consolidated billing

In an earlier module, you learned about AWS Organizations, a service that enables you to manage multiple AWS accounts from a central location. AWS Organizations also provides the option for [**consolidated billing**(opens in a new tab)](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html). 

The consolidated billing feature of AWS Organizations enables you to receive a single bill for all AWS accounts in your organization. By consolidating, you can easily track the combined costs of all the linked accounts in your organization. The default maximum number of accounts allowed for an organization is 4, but you can contact AWS Support to increase your quota, if needed.

On your monthly bill, you can review itemized charges incurred by each account. This enables you to have greater transparency into your organizationâs accounts while still maintaining the convenience of receiving a single monthly bill.

Another benefit of consolidated billing is the ability to share bulk discount pricing, Savings Plans, and Reserved Instances across the accounts in your organization. For instance, one account might not have enough monthly usage to qualify for discount pricing. However, when multiple accounts are combined, their aggregated usage may result in a benefit that applies across all accounts in the organization.

#### Bulk discount pricing example

![Three non-consolidated AWS accounts. Each uses Amazon S3 and each is under 10 TB of usage.](./assets/QLrdZx2nsSMAI-3Q_rFlBeqGAW7Kc09C2.png)

Consolidated billing also enables you to share volume pricing discounts across accounts. 

Some AWS services, such as Amazon S3, provide volume pricing discounts that give you lower prices the more that you use the service. In Amazon S3, after customers have transferred 10 TB of data in a month, they pay a lower per-GB transfer price for the next 40 TB of data transferred. 

In this example, there are three separate AWS accounts that have transferred different amounts of data in Amazon S3 during the current month: 

- Account 1 has transferred 2 TB of data.
- Account 2 has transferred 5 TB of data.
- Account 3 has transferred 7 TB of data.

Because no single account has passed the 10 TB threshold, none of them is eligible for the lower per-GB transfer price for the next 40 TB of data transferred.

### AWS Budgets

In [**AWS Budgets**(opens in a new tab)](https://aws.amazon.com/aws-cost-management/aws-budgets), you can create budgets to plan your service usage, service costs, and instance reservations.

The information in AWS Budgets updates three times a day. This helps you to accurately determine how close your usage is to your budgeted amounts or to the AWS Free Tier limits.

In AWS Budgets, you can also set custom alerts when your usage exceeds (or is forecasted to exceed) the budgeted amount.

### AWS Cost Explorer

[**AWS Cost Explorer**(opens in a new tab)](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/) is a tool that lets you visualize, understand, and manage your AWS costs and usage over time.

AWS Cost Explorer includes a default report of the costs and usage for your top five cost-accruing AWS services. You can apply custom filters and groups to analyze your data. For example, you can view resource usage at the hourly level.

### AWS Support

AWS offers four different [**Support plans**(opens in a new tab)](https://aws.amazon.com/premiumsupport/plans/) to help you troubleshoot issues, lower costs, and efficiently use AWS services. 

#### Basic Support

**Basic Support** is free for all AWS customers. It includes access to whitepapers, documentation, and support communities. With Basic Support, you can also contact AWS for billing questions and service limit increases.

With Basic Support, you have access to a limited selection of AWS Trusted Advisor checks. Additionally, you can use the **AWS Personal Health Dashboard**, a tool that provides alerts and remediation guidance when AWS is experiencing events that may affect you. 

#### Developer, Business, Enterprise On-Ramp, and Enterprise Support

The Developer, Business, Enterprise On-Ramp, and Enterprise Support plans include all the benefits of Basic Support, in addition to the ability to open an unrestricted number of technical support cases. These Support plans have pay-by-the-month pricing and require no long-term contracts.

In general, for pricing, the Developer plan has the lowest cost, the Business and Enterprise On-Ramp plans are in the middle, and the Enterprise plan has the highest cost.

##### Developer Support

Customers in the **Developer Support** plan have access to features such as:

- Best practice guidance
- Client-side diagnostic tools
- Building-block architecture support, which consists of guidance for how to use AWS offerings, features, and services together
- Supports an unlimited number of support cases that can be opened by one primary contact, which is the [AWS account *root user*](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html).

For example, suppose that your company is exploring AWS services. Youâve heard about a few different AWS services. However, youâre unsure of how to potentially use them together to build applications that can address your companyâs needs. In this scenario, the building-block architecture support that is included with the Developer Support plan could help you to identify opportunities for combining specific services and features.

##### Business Support

Customers with a **Business Support** plan have access to additional features, including: 

- Use-case guidance to identify AWS offerings, features, and services that can best support your specific needs
- All AWS Trusted Advisor checks
- The AWS Support API to interact with Support Center and Trusted Advisor. You can use the AWS Support API to automate support case management and Trusted Advisor operations.
- Third-party software support â Help with Amazon Elastic Compute Cloud (Amazon EC2) instance operating systems and configuration. Also, help with the performance of the most popular third-party software components on AWS. Third-party software support isn't available for customers on Basic or Developer Support plans.
- Supports an unlimited number of AWS Identity and Access Management (IAM) users who can open technical support cases.

Suppose that your company has the Business Support plan and wants to install a common third-party operating system onto your Amazon EC2 instances. You could contact AWS Support for assistance with installing, configuring, and troubleshooting the operating system. For advanced topics such as optimizing performance, using custom scripts, or resolving security issues, you may need to contact the third-party software provider directly.

##### Enterprise On-Ramp Support

In November 2021, AWS opened enrollment into AWS Enterprise On-Ramp Support plan. In addition to all the features included in the Basic, Developer, and Business Support plans, customers with an Enterprise On-Ramp Support plan have access to:

- A pool of Technical Account Managers to provide proactive guidance and coordinate access to programs and AWS experts
- A Cost Optimization workshop (one per year)
- A Concierge support team for billing and account assistance
- Tools to monitor costs and performance through Trusted Advisor and Health API/Dashboard

Enterprise On-Ramp Support plan also provides access to a specific set of proactive support services, which are provided by a pool of Technical Account Managers.

- Consultative review and architecture guidance (one per year)
- Infrastructure Event Management support (one per year)
- Support automation workflows
- 30 minutes or less response time for business-critical issues

##### Enterprise Support

In addition to all features included in the Basic, Developer, Business, and Enterprise On-Ramp support plans, customers with Enterprise Support have access to:

- A designated Technical Account Manager to provide proactive guidance and coordinate access to programs and AWS experts
- A Concierge support team for billing and account assistance
- Operations Reviews and tools to monitor health
- Training and Game Days to drive innovation
- Tools to monitor costs and performance through Trusted Advisor and Health API/Dashboard

The Enterprise plan also provides full access to proactive services, which are provided by a designated Technical Account Manager:

- Consultative review and architecture guidance
- Infrastructure Event Management support
- Cost Optimization Workshop and tools
- Support automation workflows
- 15 minutes or less response time for business-critical issues

### Technical Account Manager (TAM)

The Enterprise On-Ramp and Enterprise Support plans include access to a **Technical Account Manager (TAM)**.

The TAM is your primary point of contact at AWS. If your company subscribes to Enterprise Support or Enterprise On-Ramp, your TAM educates, empowers, and evolves your cloud journey across the full range of AWS services. TAMs provide expert engineering guidance, help you design solutions that efficiently integrate AWS services, assist with cost-effective and resilient architectures, and provide direct access to AWS programs and a broad community of experts.

For example, suppose that you are interested in developing an application that uses several AWS services together. Your TAM could provide insights into how to best use the services together. They achieve this, while aligning with the specific needs that your company is hoping to address through the new application.

### AWS Marketplace

[**AWS Marketplace**(opens in a new tab)](https://aws.amazon.com/marketplace) is a digital catalog that includes thousands of software listings from independent software vendors. You can use AWS Marketplace to find, test, and buy software that runs on AWS. 

For each listing in AWS Marketplace, you can access detailed information on pricing options, available support, and reviews from other AWS customers.

You can also explore software solutions by industry and use case. For example, suppose your company is in the healthcare industry. In AWS Marketplace, you can review use cases that software helps you to address, such as implementing solutions to protect patient records or using machine learning models to analyze a patientâs medical history and predict possible health risks.

## Module 9 Migration and Innovation

#### Six core perspectives of the Cloud Adoption Framework

At the highest level, the [**AWS Cloud Adoption Framework (AWS CAF)**(opens in a new tab)](https://d1.awsstatic.com/whitepapers/aws_cloud_adoption_framework.pdf) organizes guidance into six areas of focus, called **P****erspectives**. Each Perspective addresses distinct responsibilities. The planning process helps the right people across the organization prepare for the changes ahead.

In general, the **Business**, **People**, and **Governance** Perspectives focus on business capabilities, whereas the **Platform**, **Security**, and **Operations** Perspectives focus on technical capabilities.

#### 6 strategies for migration

When migrating applications to the cloud, six of the most common [migration strategies(opens in a new tab)](https://aws.amazon.com/blogs/enterprise-strategy/6-strategies-for-migrating-applications-to-the-cloud/) that you can implement are:

- Rehosting

  - **Rehosting** also known as âlift-and-shiftâ involves moving applications without changes. 

    In the scenario of a large legacy migration, in which the company is looking to implement its migration and scale quickly to meet a business case, the majority of applications are rehosted

- Replatforming

  - **Replatforming**, also known as âlift, tinker, and shift,â involves making a few cloud optimizations to realize a tangible benefit. Optimization is achieved without changing the core architecture of the application.
  - e.g. Move your DB to Amazon RDS

- Refactoring/re-architecting

  - **Refactoring** (also known as **re-architecting**) involves reimagining how an application is architected and developed by using cloud-native features. Refactoring is driven by a strong business need to add features, scale, or performance that would otherwise be difficult to achieve in the applicationâs existing environment.

- Repurchasing

  - **Repurchasing** involves moving from a traditional license to a software-as-a-service model. 

    For example, a business might choose to implement the repurchasing strategy by migrating from a customer relationship management (CRM) system to Salesforce.com.

- Retaining

  - **Retaining** consists of keeping applications that are critical for the business in the source environment. This might include applications that require major refactoring before they can be migrated, or, work that can be postponed until a later time.

- Retiring

  - **Retiring** is the process of removing applications that are no longer needed.

### AWS Snow Family members

The [**AWS Snow Family**(opens in a new tab)](https://aws.amazon.com/snow) is a collection of physical devices that help to physically transport up to exabytes of data into and out of AWS. 

AWS Snow Family is composed of **AWS Snowcone**, **AWS Snowball**, and **AWS Snowmobile**. 

![img](./assets/HS_OOF4i0ImXRQQB_IIcwz3-CkuSyAs0F.jpg)



These devices offer different capacity points, and most include built-in computing capabilities. AWS owns and manages the Snow Family devices and integrates with AWS security, monitoring, storage management, and computing capabilities.  

#### AWS Snowcone

[**AWS Snowcone**(opens in a new tab)](https://aws.amazon.com/snowcone) is a small, rugged, and secure edge computing and data transfer device. 

It features 2 CPUs, 4 GB of memory, and up to 14 TB of usable storage.

#### AWS Snowball

[**AWS Snowball**(opens in a new tab)](https://aws.amazon.com/snowball/) offers two types of devices:

- Snowball Edge Storage Optimized 

  devices are well suited for large-scale data migrations and recurring transfer workflows, in addition to local computing with higher capacity needs. 

  - Storage: 80 TB of hard disk drive (HDD) capacity for block volumes and Amazon S3 compatible object storage, and 1 TB of SATA solid state drive (SSD) for block volumes. 
  - Compute: 40 vCPUs, and 80 GiB of memory to support Amazon EC2 sbe1 instances (equivalent to C5).

- Snowball Edge Compute Optimized 

  provides powerful computing resources for use cases such as machine learning, full motion video analysis, analytics, and local computing stacks. 

  - Storage: 80-TB usable HDD capacity for Amazon S3 compatible object storage or Amazon EBS compatible block volumes and 28 TB of usable NVMe SSD capacity for Amazon EBS compatible block volumes. 
  - Compute: 104 vCPUs, 416 GiB of memory, and an optional NVIDIA Tesla V100 GPU. Devices run Amazon EC2 sbe-c and sbe-g instances, which are equivalent to C5, M5a, G3, and P3 instances.

#### AWS Snowmobile

[**AWS Snowmobile**(opens in a new tab)](https://aws.amazon.com/snowmobile) is an exabyte-scale data transfer service used to move large amounts of data to AWS. 

You can transfer up to 100 petabytes of data per Snowmobile, a 45-foot long ruggedized shipping container, pulled by a semi trailer truck.

## Module 10 The Cloud Journey

### The AWS Well-Architected Framework

The [**AWS Well-Architected Framework**(opens in a new tab)](https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html) helps you understand how to design and operate reliable, secure, efficient, and cost-effective systems in the AWS Cloud. It provides a way for you to consistently measure your architecture against best practices and design principles and identify areas for improvement.



![img](./assets/qBr8ICsRuOZ24Gk0_sdUw4ZmqaZNIbW-P.png)



The Well-Architected Framework is based on six pillars: 

- Operational excellence
- Security
- Reliability
- Performance efficiency
- Cost optimization
- Sustainability

To learn more, expand each of the following six categories.

### Advantages of cloud computing

Operating in the AWS Cloud offers many benefits over computing in on-premises or hybrid environments. 

In this section, you will learn about six advantages of cloud computing:

- Trade upfront expense for variable expense.
- Benefit from massive economies of scale.
- Stop guessing capacity.
- Increase speed and agility.
- Stop spending money running and maintaining data centers.
- Go global in minutes.

## Module Extra 1 AI

### AWS AI Service

1. **Amazon Translate**: A neural machine translation service that delivers fast, high-quality, and affordable language translation.
2. **Amazon Polly**: Converts text into lifelike speech, enabling applications to speak in natural-sounding voices.
3. **Amazon Lex**: Builds conversational interfaces for applications using voice and text, leveraging the same technology as Alexa.
4. **Amazon Comprehend**: A natural language processing service that uncovers insights and relationships in text using machine learning.
5. **Amazon Forecast**: Employs machine learning to generate more accurate demand forecasts based on historical data patterns.
6. **Amazon CodeGuru**: An automated code review service that uses machine learning to identify critical issues and optimize code performance.
7. **Amazon Rekognition**: Provides image and video analysis, identifying objects, people, text, scenes, and activities, along with detecting inappropriate content.

### Machine Learning Services

- **Amazon SageMaker**: An integrated machine learning platform that enables developers and data scientists to build, train, and deploy machine learning models at scale.
- **AWS CodeWhisperer**: A machine learning-powered code recommendation tool that helps developers by automatically generating code suggestions and fixing bugs.

### Analytic Service

- **Amazon Athena**: An interactive query service that makes it easy to analyze data directly in Amazon S3 using standard SQL.
- **Amazon Macie**: A fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect sensitive data in AWS.
- **Amazon Kinesis**: A platform for streaming data on AWS, offering powerful services to load and analyze streaming data in real time.
- **AWS Glue**: A fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analytics.
- **Amazon QuickSight**: A fast, cloud-powered business intelligence service that makes it easy to deliver insights to everyone in your organization.
- **Amazon OpenSearch Service**: An Elasticsearch-compatible search and analytics suite designed for log analytics, real-time application monitoring, and more.
- **Amazon EMR (Elastic MapReduce)**: A cloud-native big data platform, allowing processing of vast amounts of data quickly and cost-effectively across resizable clusters of Amazon EC2 instances.



[AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/1851/play/85986/aws-technical-essentials)

## Module Extra 2 Compuete as a service

### Amazon Machine Image

When launching an EC2 instance, the first setting you configure is which operating system you want by selecting an Amazon Machine Image (AMI).

In the traditional infrastructure world, spinning up a server consists of installing an operating system from installation disks, drives, or wizards over the network. In the AWS Cloud, the operating system installation is not your responsibility. Instead, it's built into the AMI that you choose.

An AMI includes the operating system, storage mapping, architecture type, launch permissions, and any additional preinstalled software applications.

![img](./assets/zIAa0cAZ_SzWA3lp_jKOXSf3jjyOMxyyo.png)

### EC2 instance lifecycle

An EC2 instance transitions between different states from the moment you create it until its termination.



![The transition between different EC2 instance states from launch through to termination.](./assets/Xiqo31wijGzxUHcs_W-vfLyAzzrKyOEwn.png)



1. When you launch an instance, it enters the **pending** state. When an instance is pending, billing has not started. At this stage, the instance is preparing to enter the running state. Pending is where AWS performs all actions needed to set up an instance, such as copying the AMI content to the root device and allocating the necessary networking components.

2. When your instance is **running**, it's ready to use. This is also the stage where billing begins. As soon as an instance is running, you can take other actions on the instance, such as reboot, terminate, stop, and stop-hibernate.

3. When you reboot an instance, itâs different than performing a stop action and then a start action. **Rebooting** an instance is equivalent to rebooting an operating system. The instance keeps its public DNS name (IPv4) and private and public IPv4 addresses. An IPv6 address (if applicable) remains on the same host computer and maintains its public and private IP address, in addition to any data on its instance store volumes.

4. When you stop your instance, it enters the **stopping** and then **stopped** state. This is similar to when you shut down your laptop. You can stop and start an instance if it has an Amazon Elastic Block Store (Amazon EBS) volume as its root device. When you stop and start an instance, your instance can be placed on a new underlying physical server. Your instance retains its private IPv4 addresses and if your instance has an IPv6 address, it retains its IPv6 address. When you put the instance into stop-hibernate, the instance enters the stopped state, but saves the last information or content into memory, so that the start process is faster. 

   

5. When you **terminate** an instance, the instance stores are erased, and you lose both the public IP address and private IP address of the machine. Termination of an instance means that you can no longer access the machine. As soon as the status of an instance changes to **shutting down** or **terminated,** you stop incurring charges for that instance.

### Difference between stop and stop-hibernate

When you stop an instance, it enters the stopping state until it reaches the stopped state. AWS does not charge usage or data transfer fees for your instance after you stop it. But storage for any Amazon EBS volumes is still charged. While your instance is in the stopped state, you can modify some attributes, like the instance type. When you stop your instance, the data from the instance memory (RAM) is lost.

When you stop-hibernate an instance, Amazon EC2 signals the operating system to perform hibernation (suspend-to-disk), which saves the contents from the instance memory (RAM) to the EBS root volume. You can hibernate an instance only if hibernation is turned on and the instance meets the hibernation prerequisites.

## Module Extra 3 Loading balancing & Scaling

### Elastic Load Balancer

The ELB service provides a major advantage over using your own solution to do load balancing. Mainly, you donât need to manage or operate ELB. It can distribute incoming application traffic across EC2 instances, containers, IP addresses, and Lambda functions. Other key features include the following:

- **Hybrid mode â** Because ELB can load balance to IP addresses, it can work in a hybrid mode, which means it also load balances to on-premises servers.
- **High availability** - ELB is highly available. The only option you must ensure is that the load balancer's targets are deployed across multiple Availability Zones.
- **Scalability** - In terms of scalability, ELB automatically scales to meet the demand of the incoming traffic. It handles the incoming traffic and sends it to your backend application.

#### Health checks

Monitoring is an important part of load balancers because they should route traffic to only healthy EC2 instances. Thatâs why ELB supports two types of health checks as follows:

- Establishing a connection to a backend EC2 instance using TCP and marking the instance as available if the connection is successful.
- Making an HTTP or HTTPS request to a webpage that you specify and validating that an HTTP response code is returned.

#### Components of ELB

![Diagram of ELB components depicting a rule, a listener, two targets, a health check, and a target group.](./assets/9Nhe4XPfwf7BcJAR_edbUVOAV1agybbQ-.png)

- Rule: To associate a target group to a listener, you must use a rule. Rules are made up of two conditions. The first condition is the source IP address of the client. The second condition decides which target group to send the traffic to.
- Listener: The client connects to the listener. This is often called client side. To define a listener, a port must be provided in addition to the protocol, depending on the load balancer type. There can be many listeners for a single load balancer.
- Target group: The backend servers, or server side, are defined in one or more target groups. This is where you define the type of backend you want to direct traffic to, such as EC2 instances, Lambda functions, or IP addresses. Also, a health check must be defined for each target group. 

#### Types of load balancers

##### Application Load Balancer 

For our Employee Directory application, we are using an Application Load Balancer. An Application Load Balancer functions at Layer 7 of the Open Systems Interconnection (OSI) model. It is ideal for load balancing HTTP and HTTPS traffic.

You can do things similar to other load balancer like apache

- Route traffic based on request data

  - An Application Load Balancer makes routing decisions based on the HTTP and HTTPS protocol. For example, the ALB could use the URL path (/upload) and host, HTTP headers and method, or the source IP address of the client. This facilitates granular routing to target groups.

- Sends response directly to the client

  - An Application Load Balancer can reply directly to the client with a fixed response, such as a custom HTML page. It can also send a redirect to the client. This is useful when you must redirect to a specific website or redirect a request from HTTP to HTTPS. It removes that work from your backend servers.

- Uses TLS offloading

  - An Application Load Balancer understands HTTPS traffic. To pass HTTPS traffic through an Application Load Balancer, an SSL certificate is provided one of the following ways:

    - Importing a certificate by way of IAM or ACM services
    - Creating a certificate for free using ACM

    This ensures that the traffic between the client and Application Load Balancer is encrypted.

- Authenticate users

  - An Application Load Balancer can authenticate users before they can pass through the load balancer. The Application Load Balancer uses the OpenID Connect (OIDC) protocol and integrates with other AWS services to support protocols, such as the following:
    - SAML
    - Lightweight Directory Access Protocol (LDAP)
    - Microsoft Active Directory
    - Others

- Secures traffic

  - To prevent traffic from reaching the load balancer, you configure a security group to specify the supported IP address ranges.

- Supports sticky sessions

  - If requests must be sent to the same backend server because the application is stateful, use the sticky session feature. This feature uses an HTTP cookie to remember which server to send the traffic to across connections.

##### Network Load Balancer

A Network Load Balancer is ideal for load balancing TCP and UDP traffic. It functions at Layer 4 of the OSI model, routing connections from a target in the target group based on IP protocol data.

- Sticky sessions:
  - Routes requests from the same client to the same target
- Low Latency
- Source IP address
  - Preserves the client-side source IP address
- Static IP support
  - Automatically provides a static IP address per Availability Zone (subnet).
- Elastic IP address support
  - Lets users assign a custom, fixed IP address per Availability Zone (subnet).
- DNS failover
  - Uses Amazon Route 53 to direct traffic to load balancer nodes in other zones.

##### Gateway Load Balancer 

A Gateway Load Balancer helps you to deploy, scale, and manage your third-party appliances, such as firewalls, intrusion detection and prevention systems, and deep packet inspection systems. 

#### Selecting between ELB types

You can select between the ELB service types by determining which feature is required for your application. The following table presents a list of some of the major features of load balancers. For a complete list, see "Elastic Load Balancing features" in the Resources section at the end of this lesson. 

| **Feature**                          | **ALB**              | **NLB**           | **GLB**                                    |
| ------------------------------------ | -------------------- | ----------------- | ------------------------------------------ |
| **Load Balancer Type**               | Layer 7              | Layer 4           | Layer 3 gateway and Layer 4 load balancing |
| **Target Type**                      | IP, instance, Lambda | IP, instance, ALB | IP, instance                               |
| **Protocol Listeners**               | HTTP, HTTPS          | TCP, UDP, TLS     | IP                                         |
| **Static IP and Elastic IP Address** |                      | Yes               |                                            |
| **Preserve Source IP Address**       | Yes                  | Yes               | Yes                                        |
| **Fixed Response**                   | Yes                  |                   |                                            |
| **User Authentication**              | Yes                  |                   |                                            |

### Auto Scaling

The Amazon EC2 Auto Scaling service adds and removes capacity to keep a steady and predictable performance at the lowest possible cost. By adjusting the capacity to exactly what your application uses, you only pay for what your application needs. This means Amazon EC2 Auto Scaling helps scale your infrastructure and ensure high availability.

#### ELB with Amazon EC2 Auto Scaling

Additionally, the ELB service integrates seamlessly with Amazon EC2 Auto Scaling. As soon as a new EC2 instance is added to or removed from the Amazon EC2 Auto Scaling group, ELB is notified. However, before ELB can send traffic to a new EC2 instance, it needs to validate that the application running on the EC2 instance is available.

This validation is done by way of the ELB health checks feature you learned about in the previous lesson. 

#### Configure Amazon EC2 Auto Scaling components

There are three main components of Amazon EC2 Auto Scaling. Each of these components addresses one main question as follows:

- **Launch template or configuration:** Which resources should be automatically scaled?

- **Amazon EC2 Auto Scaling groups:** Where should the resources be deployed?

  - This is where you specify the Amazon Virtual Private Cloud (Amazon VPC) and subnets the EC2 instance should be launched in. Amazon EC2 Auto Scaling takes care of creating the EC2 instances across the subnets, so select at least two subnets that are across different Availability Zones.

- **Scaling policies:** When should the resources be added or removed?

  - **Simple scaling policy**: With a simple scaling policy, you use a CloudWatch alarm and specify what to do when it is invoked. 
    - After the scaling policy is invoked, it enters a cooldown period before taking any other action.

  - **Step scaling policy**: Step scaling policies respond to additional alarms even when a scaling activity or health check replacement is in progress. 
    - Similar to the previous example, you might decide to add two more instances when CPU utilization is at 85 percent and four more instances when itâs at 95 percent.
  - **Target tracking scaling policy:**
    - If your application scales based on average CPU utilization, average network utilization (in or out), or request count, then this scaling policy type is the one to use.
    - All you need to provide is the target value to track, and it automatically creates the required CloudWatch alarms.
